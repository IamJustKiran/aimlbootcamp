{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IamJustKiran/aimlbootcamp/blob/main/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download required NLTK resources\n",
        "nltk.download(\"punkt\")  # sentence and word tokenizers\n",
        "nltk.download(\"punkt_tab\")  # optional: updated tables for punkt\n",
        "\n",
        "# Sample text (corpus)\n",
        "corpus = \"\"\"Hello Welcome, to Kiran learning tutorial.\n",
        "Please do watch the entire course! to become expert in NLP.\"\"\"\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1. Sentence Tokenization\n",
        "# Splits a paragraph/text into individual sentences.\n",
        "# Uses \"PunktSentenceTokenizer\" under the hood.\n",
        "documents = nltk.sent_tokenize(corpus)\n",
        "print(\"Sentence Tokenization:\")\n",
        "print(documents)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2. Word Tokenization\n",
        "# Splits text into words (tokens) but keeps punctuation as separate tokens.\n",
        "words = nltk.word_tokenize(corpus)\n",
        "print(\"Word Tokenization (with punctuation):\")\n",
        "print(words)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3. Tokenize each sentence into words\n",
        "print(\"Sentence to Word Tokenization:\")\n",
        "for sentence in documents:\n",
        "    print(nltk.word_tokenize(sentence))\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4. WordPunctTokenizer\n",
        "# Splits words *and* punctuation into separate tokens.\n",
        "# Example: \"NLP.\" → [\"NLP\", \".\"]\n",
        "words2 = nltk.wordpunct_tokenize(corpus)\n",
        "print(\"WordPunct Tokenization (splits punctuation separately):\")\n",
        "print(words2)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5. TreebankWordTokenizer\n",
        "# More sophisticated: handles contractions & punctuation better.\n",
        "# Example: \"don't\" → [\"do\", \"n't\"], \"NLP.\" → [\"NLP\", \".\"]\n",
        "treebank_tokenizer = nltk.TreebankWordTokenizer()\n",
        "words3 = treebank_tokenizer.tokenize(corpus)\n",
        "print(\"Treebank Tokenization (handles contractions smartly):\")\n",
        "print(words3)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6. TreebankWordDetokenizer\n",
        "# Opposite of tokenization — joins a list of tokens back into text.\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "detokenizer = TreebankWordDetokenizer()\n",
        "print(\"Detokenization (joining tokens back):\")\n",
        "print(detokenizer.detokenize(words3))\n"
      ],
      "metadata": {
        "id": "9dIMRhhDT7j8",
        "outputId": "c0ad1c6c-d75c-4eb3-f3ad-41302bd62ae9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Tokenization:\n",
            "['Hello Welcome, to Kiran learning tutorial.', 'Please do watch the entire course!', 'to become expert in NLP.']\n",
            "--------------------------------------------------\n",
            "Word Tokenization (with punctuation):\n",
            "['Hello', 'Welcome', ',', 'to', 'Kiran', 'learning', 'tutorial', '.', 'Please', 'do', 'watch', 'the', 'entire', 'course', '!', 'to', 'become', 'expert', 'in', 'NLP', '.']\n",
            "--------------------------------------------------\n",
            "Sentence to Word Tokenization:\n",
            "['Hello', 'Welcome', ',', 'to', 'Kiran', 'learning', 'tutorial', '.']\n",
            "['Please', 'do', 'watch', 'the', 'entire', 'course', '!']\n",
            "['to', 'become', 'expert', 'in', 'NLP', '.']\n",
            "--------------------------------------------------\n",
            "WordPunct Tokenization (splits punctuation separately):\n",
            "['Hello', 'Welcome', ',', 'to', 'Kiran', 'learning', 'tutorial', '.', 'Please', 'do', 'watch', 'the', 'entire', 'course', '!', 'to', 'become', 'expert', 'in', 'NLP', '.']\n",
            "--------------------------------------------------\n",
            "Treebank Tokenization (handles contractions smartly):\n",
            "['Hello', 'Welcome', ',', 'to', 'Kiran', 'learning', 'tutorial.', 'Please', 'do', 'watch', 'the', 'entire', 'course', '!', 'to', 'become', 'expert', 'in', 'NLP', '.']\n",
            "--------------------------------------------------\n",
            "Detokenization (joining tokens back):\n",
            "Hello Welcome, to Kiran learning tutorial. Please do watch the entire course! to become expert in NLP.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}